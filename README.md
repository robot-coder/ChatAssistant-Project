# Chat Assistant

This project implements a Chat Assistant using FastAPI and a JavaScript front-end. The assistant allows users to interact with various LLMs and supports continuous conversations.

## Features
- Front-end built with JavaScript
- Back-end powered by FastAPI
- Integration with LiteLLM for LLM calls
- Continuous conversation support
- Deployment on Render.com

## Deployment
The Chat Assistant is deployed on Render.com. You can access it [here](#).

## Getting Started
1. Clone the repository.
2. Install dependencies for both front-end and back-end.
3. Run the FastAPI server.
4. Open the front-end in your browser.

## Extensions
- Text file uploads for prompt context.
- Image file uploads for multimodal LLMs.
- Side-by-side LLM response comparison.

## License
This project is licensed under the MIT License.